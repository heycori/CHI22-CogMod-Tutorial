{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6e1a00a",
   "metadata": {},
   "source": [
    "# Modeling Workflow\n",
    "In this module, we cover the modeling workflow from defining the model, running simulations, evaluating the model, and using it for optimization. The learning outcomes of this module are:\n",
    "\n",
    "* Understand modeling workflow, with an ability to provide a detailed case example\n",
    "* Be able to use a reinforcement learning model of multitasking while driving\n",
    "* Be able to use Bayesian likelihood free inference to fit model parameters\n",
    "* Understand how parameterized simulation models can be used to explore design candidates\n",
    "\n",
    "The workflow used in this notebook can be illustrated like this.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<div>\n",
    "<img src=\"workflow.png\" width=\"800\">\n",
    "</div>\n",
    "\n",
    "Please note that this is not a general workflow that can be used to describe every model, but a description of the process of this notebook. For a more general theory of modeling workflow, you can read this Wilson & Collins 2019 paper: https://elifesciences.org/articles/49547\n",
    "\n",
    "**Note**. The word \"model\" has multiple meanings. A model can refer to the whole interactive task, including the user, or it can refer to just the user's cognition, or it can even refer to a specific internal model that the user has of the task. In this notebook, from now on, we will be using the following exact (but narrow) definitions.\n",
    "\n",
    "* An *agent* takes actions to reach goals.\n",
    "* The agent utilises a *policy*, which tells what the agent does in a particular state.\n",
    "* The agent is expected to follow a *bounded optimal policy*, meaning it generally does what is best for it in the long term.\n",
    "* The agent interacts with an *environment*, which for our computational is formalised. The resulting interaction of the formalised environment and the agent is called *simulation* of the interactive task.\n",
    "* The agent has an internal representation of the dynamics of the environment. Here, we call that a *model*, which, given the current state of the environment and an action taken by the agent, provides a prediction of what the next state will be.  \n",
    "\n",
    "## Case: Multitasking while Driving\n",
    "The module will make use of a computational cognitive model that simulates driver multitasking (Jokinen, Kujala, & Oulasvirta 2021: https://journals.sagepub.com/doi/10.1177/0018720820927687\n",
    "\n",
    "The model architecture takes the form of hierarchical control system, where different parts of the hierarchy are responsible for managing one part of the overall task. As illustrated above, the task is accomplished by three components.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<div>\n",
    "<img src=\"driving.png\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Each \"box\" is its own RL agent, responsible only for its own task: driving (the primary task), in-car visual search (the secondary task), or supervision (deciding which task to attend). The isolation of these agents makes it possible to define each one separately from all others. Next, we define the driving task by following the modeling workflow outlined in the figure. Appendix 1 contains a walkthrough of how to create the full task model.\n",
    "\n",
    "Driving in a naturalistic setting is a complicated task, which involves a large number of relevant environmental features, such as details about the road, other traffic, pedestrians, street signs, driving speed, orientation of the steering wheel, amount of fuel left, etc. In order to simplify the task into a manageable simulation, we here reduce the task to its simplest form. We define driving as a control task, where the car has a position on the lane. Depending on the speed $S$ of the car and angle of the steering wheel $\\omega$, the next position $x$ of the car on the lane is dictated by its previous position.\n",
    "\n",
    "$$ x_{t+1} = x_t + sin(\\omega) \\cdot S \\cdot \\tau, $$\n",
    "\n",
    "where $\\tau$ is a constant indicating the length of one tick of the simulation in seconds.\n",
    "\n",
    "We can then define the driver *agent*. At any time step $t$ the agent can take actions $\\omega_t \\in [\\omega_{min},\\omega_{max}]$ to steer the car. It receives a real-valued reward based on the position of the car on the lane: if the position at a time step $x_t$ is less than $x_min$ or more than $x_max$, the agent receives a negative reward. Otherwise it receives a reward of zero.\n",
    "\n",
    "We can now implement a simplified version of the driving environment and agent. Please note that this is not the full model, but is used here for demonstrative purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "21572525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the driver from the scratch\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class driver(Env):\n",
    "    def __init__(self, speed = 17, oob_reward = -1):\n",
    "        self.speed = speed # m/s\n",
    "        self.oob_reward = oob_reward # reward from lane violation\n",
    "        \n",
    "        self.threshold = 0.2 # oob\n",
    "        \n",
    "        self.step_time = 0.1 # seconds\n",
    "        \n",
    "        # Steering wheel extrema\n",
    "        self.max_steer = 0.025\n",
    "        # How many discrete steering actions\n",
    "        self.actions = 10\n",
    "        # Action related noise\n",
    "        self.action_noise = 0\n",
    "        \n",
    "        self.action_space = Discrete(self.actions)\n",
    "        \n",
    "        # Observe current lane position\n",
    "        self.observation_space = Box(low=0, high=1, shape = (1,))\n",
    "        \n",
    "        self.log = False\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.x = 0.5 # in the middle of the lane\n",
    "        self.time = 0\n",
    "        self.trace = {}\n",
    "        self.trace[\"action\"] = []\n",
    "        self.trace[\"x\"] = []\n",
    "        return [self.x]\n",
    "    \n",
    "    # Given a discrete action, return a true steering position\n",
    "    def action_to_steer(self, action):\n",
    "        a = self.action_space.n/2\n",
    "        return (action-a)*self.max_steer/a\n",
    "    \n",
    "    def update_car_pos(self, action):\n",
    "        steer = self.action_to_steer(action)\n",
    "        # Add action related noise\n",
    "        steer += abs(steer)*np.random.logistic(0, self.action_noise)\n",
    "        # Limit steer\n",
    "        steer = min(max(steer, -self.max_steer), self.max_steer)\n",
    "        self.x += math.sin(steer) * self.speed * self.step_time\n",
    "        \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        \n",
    "        self.update_car_pos(action)\n",
    "        \n",
    "        if self.log:\n",
    "            self.trace[\"action\"].append(action)\n",
    "            self.trace[\"x\"].append(self.x)\n",
    "        \n",
    "        if self.x < self.threshold or self.x > 1 - self.threshold:\n",
    "            reward = self.oob_reward\n",
    "        else:\n",
    "            reward = 0\n",
    "            \n",
    "        # Limit x\n",
    "        self.x = max(min(self.x,1),0)\n",
    "\n",
    "        return [self.x], reward, done, {}\n",
    "    \n",
    "    def plot_trace(self):\n",
    "        plt.close()\n",
    "        plt.ylim(0,1)\n",
    "        ax = plt.gca()\n",
    "        ax.invert_yaxis()\n",
    "        t = np.linspace(0,len(self.trace[\"x\"])*self.step_time, len(self.trace[\"x\"]))\n",
    "        plt.scatter(t, self.trace[\"x\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3c3015b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's try the driving task!\n",
    "\n",
    "d = driver(17)\n",
    "d.log = True\n",
    "d.reset()\n",
    "d.step(1) # hard left steer\n",
    "d.step(1) # hard left steer\n",
    "d.step(5) # drive forward\n",
    "d.step(5) # drive forward\n",
    "d.step(5) # drive forward\n",
    "d.step(5) # drive forward\n",
    "d.step(9) # hard right steer\n",
    "d.plot_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f85fbb",
   "metadata": {},
   "source": [
    "Now that a very simple driving environment and agent have been defined, we can train a RL model. We'll use PPO for faster convergence than the original paper, which used tabular Q learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fd7afcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f132ff5b9d0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "d.log = False\n",
    "d_agent = PPO(\"MlpPolicy\", d, device=\"cpu\", verbose = 0)\n",
    "\n",
    "d_agent.learn(total_timesteps = 10000) # This is going to take a couple of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a2366e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a trace from the agent.\n",
    "def simulate_driver(driver, agent, timesteps = 1000):\n",
    "    driver.log = True\n",
    "    state = driver.reset()\n",
    "    for i in range(timesteps):\n",
    "        action, _ = agent.predict(state)\n",
    "        state , _, _, _ = driver.step(action)\n",
    "    driver.plot_trace()\n",
    "    driver.log = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8046d38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "simulate_driver(d, d_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5969bf6",
   "metadata": {},
   "source": [
    "## Introducing Bounds\n",
    "\n",
    "Now that the environmental dynamcis and the agent's goals and available actions have been defined, we can ask: how to make the RL agent behave more like a human? To that end, we should specify bounds.\n",
    "\n",
    "We start with action related noise: larger steering wheel angles are associated with more noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e905ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = driver(17)\n",
    "d.action_noise = 0.02\n",
    "d_agent = PPO(\"MlpPolicy\", d, device=\"cpu\", verbose = 0)\n",
    "\n",
    "d_agent.learn(total_timesteps = 50000) # This is going to take about 60 seconds.\n",
    "simulate_driver(d, d_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f9883a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_experiment\n",
    "import multitasking_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d72ff",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "\n",
    "Now that we have defined the full model architecture for multitasking while driving, we can use it to produce simulated results and evaluate the face-validity of these results. We will be focusing on two face-valid hypotheses. First, increasing driving speed should result in shorter in-car glance duration. Second, prioritising driving safety should result in more time spent driving at the cost of the secondary task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ce3c14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"speed\": 17,\n",
    "          \"obs_prob\": 0.8,\n",
    "          \"an\": 0.01,\n",
    "          \"sn\": 0.02,\n",
    "          \"or\": -1,\n",
    "          \"cols\": 3,\n",
    "          \"rows\": 3,\n",
    "          \"fr\": 10}\n",
    "\n",
    "# Running this will take about 10 minutes.\n",
    "trace = multitasking_agent.summarise_trace(run_experiment.run_experiment(params, 1200, max_iters = 20))\n",
    "print(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "48278a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 1, 0.3325275315605694, 597.3966744615263)\n"
     ]
    }
   ],
   "source": [
    "print(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da7e1cb",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "The model for multitasking while driving contains multiple parameters. Most of them are specified based on the description of the task environment (e.g., speed), some are based on literature (e.g., eye movement times), but some can be used to describe individuals. For instance, action related noise can be argued to be a parameter, that varies in the population. Perhaps age, or motor control problems, are associated with it. Or, it could simply be that more experienced drivers have less noisy behaviours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e281190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
