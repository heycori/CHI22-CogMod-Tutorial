{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e1a00a",
   "metadata": {},
   "source": [
    "# MODULE 4: Modeling Workflow\n",
    "In this module, we cover the modeling workflow from defining the model, running simulations, evaluating the model, and using it for optimization. The learning outcomes of this module are:\n",
    "\n",
    "* Understand modeling workflow, with an ability to provide a detailed case example\n",
    "* Be able to use a reinforcement learning model of multitasking while driving\n",
    "* Be able to use Bayesian likelihood free inference to fit model parameters\n",
    "* Understand how parameterized simulation models can be used to explore design candidates\n",
    "\n",
    "Why workflow? 1. Clear plan (knowing what to do, avoiding hacks). 2. Reproducability (clarity, transparency)\n",
    "\n",
    "The workflow used in this notebook can be illustrated like this.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/howesa/CHI22-CogMod-Tutorial/main/04-Workflow/workflow.png\" width=\"800\">\n",
    "</div>\n",
    "\n",
    "Please note that this is not a general workflow that can be used to describe every model, but a description of the process of this notebook. For a more general theory of modeling workflow, you can read this Wilson & Collins 2019 paper: https://elifesciences.org/articles/49547\n",
    "\n",
    "**Note**. The word \"model\" has multiple meanings. A model can refer to the whole interactive task, including the user, or it can refer to just the user's cognition, or it can even refer to a specific internal model that the user has of the task. In this notebook, from now on, we will be using the following exact (but narrow) definitions.\n",
    "\n",
    "* An *agent* takes actions to reach goals.\n",
    "* The agent utilises a *policy*, which tells what the agent does in a particular state.\n",
    "* The agent is expected to follow a *bounded optimal policy*, meaning it generally does what is best for it in the long term.\n",
    "* The agent interacts with an *environment*, which for our computational is formalised. The resulting interaction of the formalised environment and the agent is called *simulation* of the interactive task.\n",
    "* The agent has an internal representation of the dynamics of the environment. Here, we call that a *model*, which, given the current state of the environment and an action taken by the agent, provides a prediction of what the next state will be.  \n",
    "\n",
    "## Case: Multitasking while Driving\n",
    "The module will make use of a computational cognitive model that simulates driver multitasking (Jokinen, Kujala, & Oulasvirta 2021: https://journals.sagepub.com/doi/10.1177/0018720820927687\n",
    "\n",
    "The model architecture takes the form of hierarchical control system, where different parts of the hierarchy are responsible for managing one part of the overall task. As illustrated above, the task is accomplished by three components.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/howesa/CHI22-CogMod-Tutorial/main/04-Workflow/driving.png\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "Each \"box\" is its own RL agent, responsible only for its own task: driving (the primary task), in-car visual search (the secondary task), or supervision (deciding which task to attend). The isolation of these agents makes it possible to define each one separately from all others. Next, we define the driving task by following the modeling workflow outlined in the figure. Appendix 1 contains a walkthrough of how to create the full task model.\n",
    "\n",
    "Driving in a naturalistic setting is a complicated task, which involves a large number of relevant environmental features, such as details about the road, other traffic, pedestrians, street signs, driving speed, orientation of the steering wheel, amount of fuel left, etc. In order to simplify the task into a manageable simulation, we here reduce the task to its simplest form. We define driving as a control task, where the car has a position on the lane. Depending on the speed $S$ of the car and angle of the steering wheel $\\omega$, the next position $x$ of the car on the lane is dictated by its previous position.\n",
    "\n",
    "$$ x_{t+1} = x_t + sin(\\omega) \\cdot S \\cdot \\tau, $$\n",
    "\n",
    "where $\\tau$ is a constant indicating the length of one tick of the simulation in seconds.\n",
    "\n",
    "We can then define the driver *agent*. At any time step $t$ the agent can take actions $\\omega_t \\in [\\omega_{min},\\omega_{max}]$ to steer the car. It receives a real-valued reward based on the position of the car on the lane: if the position at a time step $x_t$ is less than $x_min$ or more than $x_max$, the agent receives a negative reward. Otherwise it receives a reward of zero.\n",
    "\n",
    "We can now implement a simplified version of the driving environment and agent. Please note that this is not the full model, but is used here for demonstrative purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0da2e401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "# Run this block of code first if you are on Colab!\n",
    "! wget https://raw.githubusercontent.com/howesa/CHI22-CogMod-Tutorial/main/04-Workflow/driver.py\n",
    "! wget https://raw.githubusercontent.com/howesa/CHI22-CogMod-Tutorial/main/04-Workflow/driver_agent.py\n",
    "! wget https://raw.githubusercontent.com/howesa/CHI22-CogMod-Tutorial/main/04-Workflow/driver_env.py\n",
    "! wget https://raw.githubusercontent.com/howesa/CHI22-CogMod-Tutorial/main/04-Workflow/search.py\n",
    "! wget https://raw.githubusercontent.com/howesa/CHI22-CogMod-Tutorial/main/04-Workflow/search_agent.py\n",
    "! wget https://raw.githubusercontent.com/howesa/CHI22-CogMod-Tutorial/main/04-Workflow/multitasking.py\n",
    "! wget https://raw.githubusercontent.com/howesa/CHI22-CogMod-Tutorial/main/04-Workflow/multitasking_agent.py\n",
    "! wget https://raw.githubusercontent.com/howesa/CHI22-CogMod-Tutorial/main/04-Workflow/precomputed_pred.py\n",
    "! wget https://raw.githubusercontent.com/howesa/CHI22-CogMod-Tutorial/main/04-Workflow/run_experiment.py\n",
    "    \n",
    "! pip install stable_baselines3\n",
    "! pip install elfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e316e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the driver from the scratch\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class driver(Env):\n",
    "    def __init__(self, speed = 17, oob_reward = -1):\n",
    "        self.speed = speed # m/s\n",
    "        self.oob_reward = oob_reward # reward from lane violation\n",
    "        \n",
    "        self.threshold = 0.2 # oob\n",
    "        \n",
    "        self.step_time = 0.1 # seconds\n",
    "        \n",
    "        # Steering wheel extrema\n",
    "        self.max_steer = 0.025\n",
    "        # How many discrete steering actions\n",
    "        self.actions = 10\n",
    "        # Action related noise\n",
    "        self.action_noise = 0\n",
    "        \n",
    "        # Steering noise\n",
    "        self.steer_noise = 0\n",
    "        \n",
    "        self.action_space = Discrete(self.actions)\n",
    "        \n",
    "        # Observe current lane position\n",
    "        self.observation_space = Box(low=0, high=1, shape = (1,))\n",
    "        \n",
    "        self.log = False\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.x = 0.5 # in the middle of the lane\n",
    "        self.time = 0\n",
    "        self.trace = {}\n",
    "        self.trace[\"action\"] = []\n",
    "        self.trace[\"x\"] = []\n",
    "        return [self.x]\n",
    "    \n",
    "    # Given a discrete action, return a true steering position\n",
    "    def action_to_steer(self, action):\n",
    "        a = self.action_space.n/2\n",
    "        return (action-a)*self.max_steer/a\n",
    "    \n",
    "    def update_car_pos(self, action):\n",
    "        steer = self.action_to_steer(action)\n",
    "        # Add action related noise\n",
    "        steer += abs(steer)*np.random.logistic(0, self.action_noise)\n",
    "        # Add non-action related noise.\n",
    "        steer += np.random.logistic(0, self.steer_noise)\n",
    "\n",
    "        # Limit steer\n",
    "        steer = min(max(steer, -self.max_steer), self.max_steer)\n",
    "        self.x += math.sin(steer) * self.speed * self.step_time\n",
    "        \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        \n",
    "        self.update_car_pos(action)\n",
    "        \n",
    "        if self.log:\n",
    "            self.trace[\"action\"].append(action)\n",
    "            self.trace[\"x\"].append(self.x)\n",
    "        \n",
    "        if self.x < self.threshold or self.x > 1 - self.threshold:\n",
    "            reward = self.oob_reward\n",
    "        else:\n",
    "            reward = 0\n",
    "            \n",
    "        # Limit x\n",
    "        self.x = max(min(self.x,1),0)\n",
    "\n",
    "        return [self.x], reward, done, {}\n",
    "    \n",
    "    def plot_trace(self):\n",
    "        plt.close()\n",
    "        plt.ylim(0,1)\n",
    "        ax = plt.gca()\n",
    "        ax.invert_yaxis()\n",
    "        oob = np.greater(self.trace[\"x\"], 1 - self.threshold) + np.greater(self.threshold, self.trace[\"x\"])\n",
    "        t = np.linspace(0,len(self.trace[\"x\"])*self.step_time, len(self.trace[\"x\"]))\n",
    "        plt.scatter(t, self.trace[\"x\"], c = oob)\n",
    "        \n",
    "    def summarize_trace(self):\n",
    "        ret = {}\n",
    "        ret[\"sd\"] = np.std(self.trace[\"x\"])\n",
    "        outside = np.sum(np.greater(self.trace[\"x\"], 1 - self.threshold))\n",
    "        outside += np.sum(np.greater(self.threshold, self.trace[\"x\"]))\n",
    "\n",
    "        ret[\"oob\"] = outside / len(self.trace[\"x\"])\n",
    "        \n",
    "        ret[\"sd_of_action\"] = np.std(self.trace[\"action\"])\n",
    "        \n",
    "        return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the driving task!\n",
    "\n",
    "d = driver(17)\n",
    "d.log = True\n",
    "d.reset()\n",
    "for i in range(10):\n",
    "    d.step(1) # hard left steer\n",
    "for i in range(10):\n",
    "    d.step(9) # hard steer right\n",
    "for i in range(10):\n",
    "    d.step(5) # drive straight\n",
    "\n",
    "d.plot_trace()\n",
    "d.summarize_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729907d6",
   "metadata": {},
   "source": [
    "Now that a very simple driving environment and agent have been defined, we can train a RL model. We'll use PPO for faster convergence than the original paper, which used tabular Q learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8efc018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "d.log = False\n",
    "d_agent = PPO(\"MlpPolicy\", d, verbose = 0)\n",
    "\n",
    "d_agent.learn(total_timesteps = 10000) # This is going to take a couple of seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a trace from the agent.\n",
    "def simulate_driver(driver, agent, timesteps = 1000):\n",
    "    driver.log = True\n",
    "    state = driver.reset()\n",
    "    for i in range(timesteps):\n",
    "        action, _ = agent.predict(state)\n",
    "        state , _, _, _ = driver.step(action)\n",
    "    driver.plot_trace()\n",
    "    driver.log = False\n",
    "    return driver.summarize_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec4e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_driver(d, d_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ade234",
   "metadata": {},
   "source": [
    "## Introducing Bounds\n",
    "\n",
    "Now that the environmental dynamcis and the agent's goals and available actions have been defined, we can ask: how to make the RL agent behave more like a human? To that end, we should specify bounds.\n",
    "\n",
    "We start with action related noise: larger steering wheel angles are associated with more noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa4d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = driver(17)\n",
    "d.action_noise = 0.02\n",
    "d.steer_noise = 0.02\n",
    "d_agent = PPO(\"MlpPolicy\", d, verbose = 0)\n",
    "\n",
    "d_agent.learn(total_timesteps = 50000) # This is going to take about 60 seconds.\n",
    "simulate_driver(d, d_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb46200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_experiment\n",
    "import multitasking_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f5386",
   "metadata": {},
   "source": [
    "# Forward Modeling\n",
    "\n",
    "Now that we have defined the full model architecture for multitasking while driving, we can use it to produce simulated results and evaluate the face-validity of these results. We will be focusing on two face-valid hypotheses. First, increasing driving speed should result in shorter in-car glance duration. Second, prioritising driving safety should result in more time spent driving at the cost of the secondary task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b305cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"speed\": 17,\n",
    "          \"obs_prob\": 0.8,\n",
    "          \"an\": 0.01,\n",
    "          \"sn\": 0.02,\n",
    "          \"or\": -1,\n",
    "          \"cols\": 3,\n",
    "          \"rows\": 3,\n",
    "          \"fr\": 10}\n",
    "\n",
    "# Running this will take about 10 minutes.\n",
    "trace = multitasking_agent.summarise_trace(run_experiment.run_experiment(params, 1200, max_iters = 20))\n",
    "print(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76f15dd",
   "metadata": {},
   "source": [
    "# 3. Inference\n",
    "\n",
    "*Parameter inference* refers to identifying values that are theoretically plausible and lead to realistic predictions. This is an *inverse modeling* problem: given observed behaviour, what are the plausible parameter values? In forward modeling, we pass a set of parameters $\\theta$ to a model $M$, which then outputs data predictions $D_p$. In inverse modeling, we have observed read data $D_o$, and the goal is to find out a plausible set of parameters $\\theta$, that with the model produce predictions that are close to the observations.  \n",
    "\n",
    "<div>\n",
    "<img src=\"inverse.png\" width=\"200\">\n",
    "</div>\n",
    "\n",
    "An in-press book chapter by Jokinen et al. https://www.jyu.fi/it/fi/tiedekunta/henkilosto/henkilosto/jokinen-jussi/jokinen-2021-bayesian.pdf has a thorough explanation of inverse modeling and Bayesian inference for cognitive models in HCI. Another paper by Kangasrääsiö et al https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12738 provides in-depth walkthroughs on how to infer parameters of cognitive models. Here, we will briefly cover the main points.\n",
    "\n",
    "The main reason for using Bayesian parameter inference for inverse modeling over other possible approaches is that it provides a mathematically rigorous framework for evaluating the plausibility of different parameter values. Bayesian parameter inference is grounded on the fact that we generally cannot know the exact parameter values that best describe the observed data and user(s) behind it. However, it is possible to obtain information about the parameter values, and this information can be represented as a probability distribution over the possible parameter values. Possible information about parameters $\\theta$ includes both what can be learned based on observations $D_o$, and our expectations about plausible parameter values based on what we know about the simulator model.\n",
    "\n",
    "The idea is to express, prior to making observations, what we know about the parameters as a distribution $P(\\theta)$, and then make observations to update this expectation.\n",
    "Given the prior probabilities $P(\\theta)$ and observation likelihood $P(D_o|\\theta)$, posterior probabilities are defined as\n",
    "\n",
    "$$\n",
    "  P(\\theta \\mid D_O) = \\frac{P(D_O \\mid \\theta) P(\\theta)}{P(D_O)},\n",
    "$$\n",
    "\n",
    "where $P(D_o)$ is the marginal likelihood $P(\\theta)=\\int P(D_o|\\theta)P(\\theta)d\\theta$. The posterior $P(\\theta|D_o)$ is a probability distribution over parameter values, and it represents what we know about the unknown parameters when we take into account that these parameters produced the observations $\\D_o$.\n",
    "\n",
    "We will be using Bayesian likelihood-free parameter inference using the ELFI package (https://elfi.readthedocs.io/en/latest/). \n",
    "\n",
    "## Inferring Individual Driving Ability \n",
    "\n",
    "The model for multitasking while driving contains multiple parameters. Most of them are specified based on the description of the task environment (e.g., speed), some are based on literature (e.g., eye movement times), but some can be used to describe individuals. For instance, action related noise can be argued to be a parameter, that varies in the population. Perhaps age, or motor control problems, are associated with it. Or, it could simply be that more experienced drivers have less noisy behaviours.\n",
    "\n",
    "Again, we start with the simple driving model created. For the purposes of this execrise, we will be using simulated data, not data from real humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c156d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress [==================================================] 100.0% Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import elfi\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "import precomputed_pred\n",
    "data = precomputed_pred.data\n",
    "\n",
    "# Use parametrised RL model of driving to generate summaries.\n",
    "# Optionally, supply a precomputed dataset that maps parameter \n",
    "# values to summaries.\n",
    "def generate_driving_data(steer_noise, batch_size = 1, random_state = None):\n",
    "    if data:\n",
    "        arr = np.array(list(data.keys()))        \n",
    "        d_pred = data[arr[np.abs(arr - steer_noise[0]).argmin()]] # find closest match\n",
    "    else:\n",
    "        d_agent = PPO(\"MlpPolicy\", d, verbose = 0)\n",
    "        d = driver(17)\n",
    "        d.action_noise = 0.02 # use default for this exercise\n",
    "        d.steer_noise = steer_noise\n",
    "        d_agent = PPO(\"MlpPolicy\", d, verbose = 0)\n",
    "        d_agent.learn(total_timesteps = 10000)\n",
    "        d_pred = simulate_driver(d, d_agent)\n",
    "    return d_pred\n",
    "    \n",
    "# Create the ELFI model\n",
    "elfi.new_model()\n",
    "# Almost uninformed prior\n",
    "steer_noise = elfi.Prior(scipy.stats.uniform, 0, 0.1)\n",
    "# Observations. We use imaginary observations, but in reality this would be human data.\n",
    "obs_a = {'sd': 0.15,\n",
    "         'oob': 0.01,\n",
    "         'sd_of_action': 3.0}\n",
    "obs_b = {'sd': 0.21,\n",
    "         'oob': 0.02,\n",
    "         'sd_of_action': 3.5}\n",
    "\n",
    "# The ELFI model\n",
    "Y = elfi.Simulator(generate_driving_data, steer_noise, observed = obs_b)\n",
    "\n",
    "# Summary statistics. As our data are already summarised, return it.\n",
    "# If either/both observed and predicted data were not summarised,\n",
    "# we would do that here.\n",
    "def sd_of_x(d):\n",
    "    return d[\"sd\"]\n",
    "\n",
    "S1 = elfi.Summary(sd_of_x, Y)\n",
    "d = elfi.Distance('euclidean', S1)\n",
    "\n",
    "bolfi = elfi.BOLFI(d, batch_size=1, initial_evidence=20,update_interval=10,\n",
    "                       bounds={'steer_noise':(0,0.1)}, seed = seed)\n",
    "\n",
    "\n",
    "bolfi.fit(n_evidence=100)\n",
    "\n",
    "bolfi.plot_discrepancy();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0aad05",
   "metadata": {},
   "source": [
    "The figure above shows us the discrepancy between the observed and simulated data, with smaller values indicating a better fit. The fitted ELFI model can now be sampled in order to produce a posterior for the parameter. While the discrepancy illustrated above can already be used to inspect the most plausible parameter values, the posterior provides us with a way to assess our confidence in this inference, as well as incorporate the prior.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3679cdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 chains of 500 iterations acquired. Effective sample size and Rhat for each parameter:\n",
      "steer_noise 851.7019263001401 1.0027007941936623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:xlabel='steer_noise'>], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain a sample of the posterior\n",
    "result = bolfi.sample(500, info_freq=500)\n",
    "\n",
    "result.plot_marginals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60763c",
   "metadata": {},
   "source": [
    "This posterior can be freely analysed. A point estimate, such as mean, median, or mode, can be used to set the most plausible parameter value, i.e., the value that best produces the observed behaviour, when used to parametrize the simulation model. Entropy or standard deviation can be used to assess our confidence in that point estimate, which should therefore not be used \"blindly\" as the best fit. Finally, one can sample the posterior for multiple values for the parameter, and use this sample to generate a range of predictions form the simulation model. The resulting *posterior predictive distribution* is useful in predicting the range of behaviours, given the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "867c482b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08237565360942864\n",
      "0.08239855556872466\n",
      "0.007526371697904383\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(result.samples['steer_noise']))\n",
    "print(np.median(result.samples['steer_noise']))\n",
    "print(np.std(result.samples['steer_noise']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c58278b",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdfb7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
